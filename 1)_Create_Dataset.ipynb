{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üí∏ Price Prediction Dataset Preparation (Electronics)\n",
        "\n",
        "This notebook prepares a high-quality dataset for fine-tuning and evaluating language models for product **price prediction**, using the **Electronics** category from the [Amazon Reviews 2023 dataset](https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023).\n",
        "\n",
        "\n",
        "Key steps include:\n",
        "- Loading and processing product data into structured prompts\n",
        "- Filtering examples based on token length and content quality\n",
        "- Visualizing token and price distributions\n",
        "- Splitting into training and test sets\n",
        "- Creating a `DatasetDict` compatible with Hugging Face ü§ó\n",
        "- Saving to disk with `pickle` for fast reuse\n",
        "\n",
        "> ‚ÑπÔ∏è **Note**: The full dataset available [here](https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/tree/main/raw/meta_categories)\n",
        ". For faster experimentation, we focus here on **Electronics**, but the same pipeline applies to other categories like Home Appliances or a combination of them.\n",
        "\n",
        "> ‚ö†Ô∏è **Note:** This notebook is designed to run on **CPU only** ‚Äî no GPU or TPU is required.\n",
        "\n"
      ],
      "metadata": {
        "id": "3gVpZYQYaRJ1"
      },
      "id": "3gVpZYQYaRJ1"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "id": "NN_bjlIRVhpx"
      },
      "id": "NN_bjlIRVhpx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîß System & Environment\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import pickle  # For saving/loading processed data objects\n",
        "sys.path.append('/content/sample_data')  # Add custom code directory to Python path (if needed)\n",
        "\n",
        "# üìä Data Manipulation & Visualization\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter, defaultdict  # For counting and grouping items\n",
        "\n",
        "# ü§ó Hugging Face Datasets & Hub\n",
        "from datasets import load_dataset, Dataset, DatasetDict  # Load and structure datasets\n",
        "from huggingface_hub import login  # Login for pushing datasets/models to the HF Hub\n",
        "\n",
        "# üîê Colab Integration\n",
        "from google.colab import userdata  # Securely access environment variables (e.g., HF token)\n"
      ],
      "metadata": {
        "id": "Il8iUXrbWUAe"
      },
      "id": "Il8iUXrbWUAe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîê Authenticate with Hugging Face\n",
        "\n",
        "We use a secure token from Colab's `userdata` to authenticate with Hugging Face.  \n",
        "This allows us to access private models or push datasets to the Hub.\n",
        "\n",
        "> üí° Make sure you've uploaded your token to Colab Secrets first:\n",
        ">\n",
        "> Go to ` Secrets` ‚Üí `+ Add new secret` ‚Üí Key: `HF_TOKEN`, Value: *your token*\n"
      ],
      "metadata": {
        "id": "73nbi_UJcSll"
      },
      "id": "73nbi_UJcSll"
    },
    {
      "cell_type": "code",
      "source": [
        "hf_token = userdata.get('HF_TOKEN')  # Hugging Face token stored in Colab Secrets\n",
        "login(hf_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "2L1SiV4fWqfP"
      },
      "id": "2L1SiV4fWqfP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üßπ Product Data Preprocessing Class for Price Prediction\n",
        "\n",
        "This **Item** class takes in raw product data and cleans, curates, and formats it into a prompt suitable for training or testing a language model to predict product prices."
      ],
      "metadata": {
        "id": "UY4zSfYGbCI2"
      },
      "id": "UY4zSfYGbCI2"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "from transformers import AutoTokenizer\n",
        "import re\n",
        "\n",
        "# üîß Configuration constants\n",
        "BASE_MODEL = \"meta-llama/Meta-Llama-3.1-8B\"  # Tokenizer source\n",
        "MIN_TOKENS = 150   # Minimum number of tokens required to include an item\n",
        "MAX_TOKENS = 160   # Max token cutoff before truncating\n",
        "MIN_CHARS = 300    # Minimum character length for raw product content\n",
        "CEILING_CHARS = MAX_TOKENS * 7  # Hard character ceiling for truncation\n",
        "\n",
        "class Item:\n",
        "    \"\"\"\n",
        "    An Item is a cleaned, curated datapoint of a Product with a Price.\n",
        "    It handles text cleaning, token length control, and prompt construction.\n",
        "    \"\"\"\n",
        "\n",
        "    # Tokenizer used for token counting and truncation\n",
        "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)\n",
        "\n",
        "    # Prompt structure\n",
        "    PREFIX = \"Price is $\"\n",
        "    QUESTION = \"How much does this cost to the nearest dollar?\"\n",
        "\n",
        "    # Common noisy metadata strings to be removed from the details\n",
        "    REMOVALS = [\n",
        "        '\"Batteries Included?\": \"No\"', '\"Batteries Included?\": \"Yes\"',\n",
        "        '\"Batteries Required?\": \"No\"', '\"Batteries Required?\": \"Yes\"',\n",
        "        \"By Manufacturer\", \"Item\", \"Date First\", \"Package\", \":\", \"Number of\",\n",
        "        \"Best Sellers\", \"Number\", \"Product \"\n",
        "    ]\n",
        "\n",
        "    # Expected instance variables\n",
        "    title: str\n",
        "    price: float\n",
        "    category: str\n",
        "    token_count: int = 0\n",
        "    details: Optional[str]\n",
        "    prompt: Optional[str] = None\n",
        "    include = False  # Marks if the item is usable based on filters\n",
        "\n",
        "    def __init__(self, data, price):\n",
        "        self.title = data['title']\n",
        "        self.price = price\n",
        "        self.parse(data)  # Begin processing and filtering\n",
        "\n",
        "    def scrub_details(self):\n",
        "        \"\"\"\n",
        "        Clean up the product 'details' string by removing irrelevant metadata fields.\n",
        "        \"\"\"\n",
        "        details = self.details\n",
        "        for remove in self.REMOVALS:\n",
        "            details = details.replace(remove, \"\")\n",
        "        return details\n",
        "\n",
        "    def scrub(self, stuff):\n",
        "        \"\"\"\n",
        "        Clean up text:\n",
        "        - Normalize whitespace and symbols\n",
        "        - Remove long alphanumeric codes (likely product codes)\n",
        "        \"\"\"\n",
        "        stuff = re.sub(r'[:\\[\\]\"{}„Äê„Äë\\s]+', ' ', stuff).strip()\n",
        "        stuff = stuff.replace(\" ,\", \",\").replace(\",,,\", \",\").replace(\",,\", \",\")\n",
        "        words = stuff.split(' ')\n",
        "        select = [word for word in words if len(word) < 7 or not any(char.isdigit() for char in word)]\n",
        "        return \" \".join(select)\n",
        "\n",
        "    def parse(self, data):\n",
        "        \"\"\"\n",
        "        Compose the full product text from its fields.\n",
        "        Filter based on character length and token count.\n",
        "        If it qualifies, generate the training prompt and mark it for inclusion.\n",
        "        \"\"\"\n",
        "        contents = '\\n'.join(data['description'])\n",
        "        if contents:\n",
        "            contents += '\\n'\n",
        "        features = '\\n'.join(data['features'])\n",
        "        if features:\n",
        "            contents += features + '\\n'\n",
        "        self.details = data['details']\n",
        "        if self.details:\n",
        "            contents += self.scrub_details() + '\\n'\n",
        "\n",
        "        if len(contents) > MIN_CHARS:\n",
        "            contents = contents[:CEILING_CHARS]\n",
        "            text = f\"{self.scrub(self.title)}\\n{self.scrub(contents)}\"\n",
        "            tokens = self.tokenizer.encode(text, add_special_tokens=False)\n",
        "            if len(tokens) > MIN_TOKENS:\n",
        "                tokens = tokens[:MAX_TOKENS]\n",
        "                text = self.tokenizer.decode(tokens)\n",
        "                self.make_prompt(text)\n",
        "                self.include = True\n",
        "\n",
        "    def make_prompt(self, text):\n",
        "        \"\"\"\n",
        "        Create the final training prompt (question + product content + price answer).\n",
        "        \"\"\"\n",
        "        self.prompt = f\"{self.QUESTION}\\n\\n{text}\\n\\n\"\n",
        "        self.prompt += f\"{self.PREFIX}{str(round(self.price))}.00\"\n",
        "        self.token_count = len(self.tokenizer.encode(self.prompt, add_special_tokens=False))\n",
        "\n",
        "    def test_prompt(self):\n",
        "        \"\"\"\n",
        "        Return a test version of the prompt with the price answer removed (for prediction).\n",
        "        \"\"\"\n",
        "        return self.prompt.split(self.PREFIX)[0] + self.PREFIX\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"\n",
        "        Developer-friendly string representation of the object.\n",
        "        \"\"\"\n",
        "        return f\"<{self.title} = ${self.price}>\"\n"
      ],
      "metadata": {
        "id": "slyBiaKaaM7K"
      },
      "id": "slyBiaKaaM7K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üöö ItemLoader Class for Efficient Parallel Dataset Processing\n",
        "\n",
        "This class is responsible for:\n",
        "- Loading a large category-specific dataset from Hugging Face\n",
        "- Filtering and cleaning datapoints to produce usable `Item` objects\n",
        "- Parallelizing the process using multiple CPU workers to improve speed"
      ],
      "metadata": {
        "id": "cHKF4o72bgPU"
      },
      "id": "cHKF4o72bgPU"
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
        "\n",
        "# üí∞ Price filtering thresholds\n",
        "CHUNK_SIZE = 1000\n",
        "MIN_PRICE = 0.5\n",
        "MAX_PRICE = 999.49\n",
        "\n",
        "class ItemLoader:\n",
        "    \"\"\"\n",
        "    Load and preprocess product data from the Hugging Face Amazon dataset.\n",
        "    Converts raw datapoints into clean `Item` objects using multiprocessing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name  # Category name (e.g., \"Electronics\")\n",
        "        self.dataset = None  # Will hold the raw HF dataset\n",
        "\n",
        "    def from_datapoint(self, datapoint):\n",
        "        \"\"\"\n",
        "        Try to create an Item from this datapoint.\n",
        "        Returns a valid Item object if it passes filtering, or None otherwise.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            price_str = datapoint['price']\n",
        "            if price_str:\n",
        "                price = float(price_str)\n",
        "                if MIN_PRICE <= price <= MAX_PRICE:\n",
        "                    item = Item(datapoint, price)\n",
        "                    return item if item.include else None\n",
        "        except ValueError:\n",
        "            return None  # Skip if price is missing or malformed\n",
        "\n",
        "    def from_chunk(self, chunk):\n",
        "        \"\"\"\n",
        "        Create a list of cleaned Items from a chunk of datapoints.\n",
        "        Used in parallel execution.\n",
        "        \"\"\"\n",
        "        batch = []\n",
        "        for datapoint in chunk:\n",
        "            result = self.from_datapoint(datapoint)\n",
        "            if result:\n",
        "                batch.append(result)\n",
        "        return batch\n",
        "\n",
        "    def chunk_generator(self):\n",
        "        \"\"\"\n",
        "        Generator to yield fixed-size chunks of the dataset.\n",
        "        Enables parallel processing by dividing the dataset.\n",
        "        \"\"\"\n",
        "        size = len(self.dataset)\n",
        "        for i in range(0, size, CHUNK_SIZE):\n",
        "            yield self.dataset.select(range(i, min(i + CHUNK_SIZE, size)))\n",
        "\n",
        "    def load_in_parallel(self, workers):\n",
        "        \"\"\"\n",
        "        Parallelize the item conversion process using ProcessPoolExecutor.\n",
        "        This dramatically improves performance for large datasets.\n",
        "        \"\"\"\n",
        "        results = []\n",
        "        chunk_count = (len(self.dataset) // CHUNK_SIZE) + 1\n",
        "        with ProcessPoolExecutor(max_workers=workers) as pool:\n",
        "            for batch in tqdm(pool.map(self.from_chunk, self.chunk_generator()), total=chunk_count):\n",
        "                results.extend(batch)\n",
        "\n",
        "        # Annotate each item with the dataset category\n",
        "        for result in results:\n",
        "            result.category = self.name\n",
        "\n",
        "        return results\n",
        "\n",
        "    def load(self, workers=8):\n",
        "        \"\"\"\n",
        "        Load and process the dataset from Hugging Face.\n",
        "        Uses `load_in_parallel()` to apply cleaning and filtering in parallel.\n",
        "        \"\"\"\n",
        "        start = datetime.now()\n",
        "        print(f\"Loading dataset {self.name}\", flush=True)\n",
        "\n",
        "        # Load raw category dataset (e.g., \"raw_meta_Electronics\")\n",
        "        self.dataset = load_dataset(\n",
        "            \"McAuley-Lab/Amazon-Reviews-2023\",\n",
        "            f\"raw_meta_{self.name}\",\n",
        "            split=\"full\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # Clean and convert items in parallel\n",
        "        results = self.load_in_parallel(workers)\n",
        "\n",
        "        finish = datetime.now()\n",
        "        print(f\"Completed {self.name} with {len(results):,} datapoints in {(finish-start).total_seconds()/60:.1f} mins\", flush=True)\n",
        "\n",
        "        return results\n"
      ],
      "metadata": {
        "id": "GXDp-69yarEC"
      },
      "id": "GXDp-69yarEC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1adcf323-de9d-4c24-a9c3-d7ae554d06ca",
      "metadata": {
        "id": "1adcf323-de9d-4c24-a9c3-d7ae554d06ca"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìò Dataset Strategy\n",
        "\n",
        "We have access to multiple product categories from the `McAuley-Lab/Amazon-Reviews-2023` dataset, such as:\n",
        "\n",
        "- Automotive  \n",
        "- Office Products  \n",
        "- Tools and Home Improvement  \n",
        "- Cell Phones and Accessories  \n",
        "- Toys and Games  \n",
        "- Appliances  \n",
        "- Musical Instruments  \n",
        "- **Electronics** (our primary focus)\n",
        "\n",
        "To start, we use the **Automotive** category for initial exploration because it's relatively small.\n",
        "\n",
        "Later, we will shift to the **Electronics** category as our **main dataset**, which offers a larger and more diverse set of examples, but keeping the same structure.\n",
        "\n"
      ],
      "metadata": {
        "id": "EZZkv3nyTCqS"
      },
      "id": "EZZkv3nyTCqS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "049885d4-fdfa-4ff0-a932-4a2ed73928e2",
      "metadata": {
        "id": "049885d4-fdfa-4ff0-a932-4a2ed73928e2"
      },
      "outputs": [],
      "source": [
        "df = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", f\"raw_meta_Appliances\", split=\"full\", trust_remote_code=True).to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîç Non-missing values per column:\")\n",
        "print(df.count())"
      ],
      "metadata": {
        "id": "YTHqxyGSLBxp"
      },
      "id": "YTHqxyGSLBxp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the first row of the dataset to inspect the structure and available fields:\n"
      ],
      "metadata": {
        "id": "xHoMQYPfTv1l"
      },
      "id": "xHoMQYPfTv1l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffba41b5-ddb6-4359-9790-9b2db900eee1",
      "metadata": {
        "id": "ffba41b5-ddb6-4359-9790-9b2db900eee1"
      },
      "outputs": [],
      "source": [
        "print(df.iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2b6dc50-ac5c-4cf2-af2e-968ed8ef86d7",
      "metadata": {
        "id": "e2b6dc50-ac5c-4cf2-af2e-968ed8ef86d7"
      },
      "source": [
        "## Now use the main Dataset\n",
        "\n",
        "#### Load and process the \"Electronics\" category using the custom ItemLoader class with 2 parallel workers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "items = ItemLoader(\"Electronics\").load(workers=2)"
      ],
      "metadata": {
        "id": "RfXE9Y_VOEXk"
      },
      "id": "RfXE9Y_VOEXk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e29a5ab-ca61-41cc-9b33-22d374681b85",
      "metadata": {
        "id": "3e29a5ab-ca61-41cc-9b33-22d374681b85"
      },
      "outputs": [],
      "source": [
        "print(f\"A grand total of {len(items):,} items\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Print the training prompt of the 1st item to inspect the formatted structure:\n"
      ],
      "metadata": {
        "id": "K5NMrnR7UXj8"
      },
      "id": "K5NMrnR7UXj8"
    },
    {
      "cell_type": "code",
      "source": [
        "print(items[0].prompt)"
      ],
      "metadata": {
        "id": "iShiC1-qOQ7T"
      },
      "id": "iShiC1-qOQ7T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Print the test prompt of the first item (with the price removed) to simulate inference-time input:\n"
      ],
      "metadata": {
        "id": "VAqyAiwKUjVs"
      },
      "id": "VAqyAiwKUjVs"
    },
    {
      "cell_type": "code",
      "source": [
        "print(items[0].test_prompt())"
      ],
      "metadata": {
        "id": "gJ9DXVHbOVx8"
      },
      "id": "gJ9DXVHbOVx8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualize the distribution of token counts for the generated prompts. This helps understand how long the prompts are and whether they stay within expected token limits:"
      ],
      "metadata": {
        "id": "bvYX4tZjU446"
      },
      "id": "bvYX4tZjU446"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89078cb1-9679-4eb0-b295-599b8586bcd1",
      "metadata": {
        "id": "89078cb1-9679-4eb0-b295-599b8586bcd1"
      },
      "outputs": [],
      "source": [
        "tokens = [item.token_count for item in items]\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.title(f\"Token counts: Avg {sum(tokens)/len(tokens):,.1f} and highest {max(tokens):,}\\n\")\n",
        "plt.xlabel('Length (tokens)')\n",
        "plt.ylabel('Count')\n",
        "plt.hist(tokens, rwidth=0.7, color=\"skyblue\", bins=range(0, 300, 10))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We kept token counts within this range to ensure prompts are informative enough for learning, and are short enough to keep training efficient and fast."
      ],
      "metadata": {
        "id": "ydSxe-2uVy87"
      },
      "id": "ydSxe-2uVy87"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot a histogram showing the distribution of product prices across all items:"
      ],
      "metadata": {
        "id": "CTTc1Ev3WBFl"
      },
      "id": "CTTc1Ev3WBFl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c38e0c43-9f7a-450e-a911-c94d37d9b9c3",
      "metadata": {
        "id": "c38e0c43-9f7a-450e-a911-c94d37d9b9c3"
      },
      "outputs": [],
      "source": [
        "prices = [item.price for item in items]\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.title(f\"Prices: Avg {sum(prices)/len(prices):,.1f} and highest {max(prices):,}\\n\")\n",
        "plt.xlabel('Price ($)')\n",
        "plt.ylabel('Count')\n",
        "plt.hist(prices, rwidth=0.7, color=\"blueviolet\", bins=range(0, 1000, 10))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5b6e987-83ba-4262-a082-57c6b0741062",
      "metadata": {
        "id": "e5b6e987-83ba-4262-a082-57c6b0741062"
      },
      "source": [
        "## Objective\n",
        "\n",
        "Craft a dataset which is more balanced in terms of prices. Less heavily scewed to cheap items, with an average that's higher than $72.3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b9424c1-44e0-499a-b45e-a35246655469",
      "metadata": {
        "id": "3b9424c1-44e0-499a-b45e-a35246655469"
      },
      "outputs": [],
      "source": [
        "# Group items by rounded price from $1 to $999\n",
        "# This creates a dictionary where each key is a rounded price,\n",
        "# and the value is a list of items that have that price\n",
        "\n",
        "slots = defaultdict(list)\n",
        "for item in items:\n",
        "    slots[round(item.price)].append(item)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üé≤ Sample items across price buckets ($1‚Äì$999) with balanced representation\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "sample = []\n",
        "\n",
        "for i in range(1, 1000):\n",
        "    slot = slots[i]\n",
        "    if i >= 240 or len(slot) <= 500:\n",
        "        sample.extend(slot)\n",
        "    else:\n",
        "        sample.extend(random.sample(slot, 500))\n",
        "\n",
        "print(f\"There are {len(sample):,} items in the sample\")"
      ],
      "metadata": {
        "id": "CJBkEMo7NIzU"
      },
      "id": "CJBkEMo7NIzU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the distribution of prices in sample\n",
        "\n",
        "prices = [float(item.price) for item in sample]\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.title(f\"Avg {sum(prices)/len(prices):.2f} and highest {max(prices):,.2f}\\n\")\n",
        "plt.xlabel('Price ($)')\n",
        "plt.ylabel('Count')\n",
        "plt.hist(prices, rwidth=0.7, color=\"darkblue\", bins=range(0, 1000, 10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SdpVJT_4XECK"
      },
      "id": "SdpVJT_4XECK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7aa0a3fc-d2fe-4e6e-8fdb-96913df2f588",
      "metadata": {
        "id": "7aa0a3fc-d2fe-4e6e-8fdb-96913df2f588"
      },
      "source": [
        "\n",
        "\\* LLaMA's tokenizer maps numbers 1‚Äì999 to single tokens, unlike Qwen2, Gemma, and Phi-3, which split digits. This is a helpful (but not critical) advantage for the project.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f03c0ee-3103-4603-af5c-b484884a3aa2",
      "metadata": {
        "id": "0f03c0ee-3103-4603-af5c-b484884a3aa2"
      },
      "source": [
        "## Finally\n",
        "\n",
        "It's time to break down our data into a training, test and validation dataset.\n",
        "\n",
        "It's typical to use 5%-10% of your data for testing purposes, but actually we have far more than we need at this point. We'll take 100,000 points for training, and we'll reserve 2,000 for testing, although we won't use all of them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b163ca2-18ef-4c26-8e9d-88eb55f114f6",
      "metadata": {
        "id": "3b163ca2-18ef-4c26-8e9d-88eb55f114f6"
      },
      "outputs": [],
      "source": [
        "random.seed(40)\n",
        "random.shuffle(sample)\n",
        "train = sample[:100_000]\n",
        "test = sample[100_000:102_000]\n",
        "print(f\"Divided into a training set of {len(train):,} items and test set of {len(test):,} items\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "299b9816-8885-4798-829a-69d66d60eb01",
      "metadata": {
        "id": "299b9816-8885-4798-829a-69d66d60eb01"
      },
      "outputs": [],
      "source": [
        "print(train[0].prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97222da3-9f2c-4d15-a5cd-5e5f8dbde6cc",
      "metadata": {
        "id": "97222da3-9f2c-4d15-a5cd-5e5f8dbde6cc"
      },
      "outputs": [],
      "source": [
        "print(test[0].test_prompt())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a116369-335a-412b-b70c-2add6675c2e3",
      "metadata": {
        "id": "7a116369-335a-412b-b70c-2add6675c2e3"
      },
      "outputs": [],
      "source": [
        "# Plot the distribution of prices in the first 250 test points\n",
        "\n",
        "prices = [float(item.price) for item in test[:250]]\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.title(f\"Avg {sum(prices)/len(prices):.2f} and highest {max(prices):,.2f}\\n\")\n",
        "plt.xlabel('Price ($)')\n",
        "plt.ylabel('Count')\n",
        "plt.hist(prices, rwidth=0.7, color=\"darkblue\", bins=range(0, 1000, 10))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d522d752-6f66-4786-a4dc-8ef51842558c",
      "metadata": {
        "id": "d522d752-6f66-4786-a4dc-8ef51842558c"
      },
      "source": [
        "## Finally - upload your brand new dataset\n",
        "\n",
        "Convert to prompts and upload to HuggingFace hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa11b3e5-fcf4-4efc-a573-f6f67fec3e73",
      "metadata": {
        "id": "fa11b3e5-fcf4-4efc-a573-f6f67fec3e73"
      },
      "outputs": [],
      "source": [
        "train_prompts = [item.prompt for item in train]\n",
        "train_prices = [item.price for item in train]\n",
        "test_prompts = [item.test_prompt() for item in test]\n",
        "test_prices = [item.price for item in test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b020ab1b-7153-4e5f-b8a3-d5bc2fafb6df",
      "metadata": {
        "id": "b020ab1b-7153-4e5f-b8a3-d5bc2fafb6df"
      },
      "outputs": [],
      "source": [
        "# Create a Dataset from the lists\n",
        "\n",
        "train_dataset = Dataset.from_dict({\"text\": train_prompts, \"price\": train_prices})\n",
        "test_dataset = Dataset.from_dict({\"text\": test_prompts, \"price\": test_prices})\n",
        "dataset = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"test\": test_dataset\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17639641-fb55-44e2-a463-b0b394d00f32",
      "metadata": {
        "id": "17639641-fb55-44e2-a463-b0b394d00f32"
      },
      "outputs": [],
      "source": [
        "# Uncomment these lines if you're ready to push to the hub, and replace my name with your HF username\n",
        "\n",
        "# HF_USER = \"vassilis19\"\n",
        "# DATASET_NAME = f\"{HF_USER}/pricer-electronics-data\"\n",
        "# dataset.push_to_hub(DATASET_NAME, private=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b85733ba-d165-4f07-b055-46803543edfe",
      "metadata": {
        "id": "b85733ba-d165-4f07-b055-46803543edfe"
      },
      "outputs": [],
      "source": [
        "# One more thing!\n",
        "# Let's pickle the training and test dataset so we don't have to execute all this code next time!\n",
        "\n",
        "with open('train.pkl', 'wb') as file:\n",
        "    pickle.dump(train, file)\n",
        "\n",
        "with open('test.pkl', 'wb') as file:\n",
        "    pickle.dump(test, file)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}